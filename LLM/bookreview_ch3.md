大模型的预训练需要很多数据集， 目前主要的数据集都来源于网络， wikipedia, 书籍， 开源的代码等等， 有不少已经处理好了的数据集被分享
，也有很多公司特有的一些数据集。 为了更好的实现对话， 需要专门的指令微调或者人类对齐数据集， 这些很多都需要专门标注的数据或者由大模型
生成一些合成数据， 数据的质量对最终模型的能力有决定性作用, 可以参考huggingface上的dataset, 有很多开源的数据集。

目前大模型训练的框架主要有以下选项： huggingface的tranformers集相关库， Microsoft的deepspeed, 以及Nvidia公司的Megatron LM. 


